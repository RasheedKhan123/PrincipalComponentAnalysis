{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO82VGQYjXsnDRDZ5GaiV9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RasheedKhan123/PrincipalComponentAnalysis/blob/main/LinearRegression_withPCA_and_withoutPCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CluxY0EfxL7E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class principleComponentAnalysis:\n",
        "    def __init__(self, x=None, y=None,m=None,var_retain=None):\n",
        "        # Initialize method to set the independent and dependent variables\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.m = m\n",
        "        self.var_retain = var_retain\n",
        "\n",
        "    def dimensionality(self, x):\n",
        "        # Method to get the shape of the input matrix/array\n",
        "        return x.shape\n",
        "\n",
        "    def if_matrix_invertible(self, x):\n",
        "        # Method to check if a matrix is invertible\n",
        "        try:\n",
        "            determinant = np.linalg.det(x)\n",
        "            return determinant != 0\n",
        "        except np.linalg.LinAlgError:\n",
        "            return False\n",
        "\n",
        "    def scale(self,x):\n",
        "        if self.x is not None:\n",
        "            return (x - x.mean()) / x.std()\n",
        "        else:\n",
        "            raise ValueError(\"Input data 'x' is not provided.\")\n",
        "\n",
        "    def find_eigens(self,x):\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(x)\n",
        "        return eigenvalues,eigenvectors\n",
        "\n",
        "    def principle_components(self, x , m = None, var_retain = None):\n",
        "        #finding covariance matrix\n",
        "        covmat = np.matmul(x.T,x)\n",
        "        lambd, a = self.find_eigens(covmat)\n",
        "        # sort it\n",
        "        order = np.argsort(lambd)[::-1]\n",
        "        lambd = lambd[order]\n",
        "        a = a[:,order]\n",
        "        if m is not None:\n",
        "          transform_matrix = a[:,:m]\n",
        "          return np.matmul(x, transform_matrix)\n",
        "        elif var_retain is not None:\n",
        "          cumulative_variance = np.cumsum(lambd) / np.sum(lambd)\n",
        "          m = np.argmax(cumulative_variance >= var_retain) + 1\n",
        "          transformed_matrix = a[:,:m]\n",
        "          return np.matmul(x, transformed_matrix)\n",
        "        else:\n",
        "          raise ValueError(\"You must provide either 'm' or 'var_retain'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Linear Regression class\n",
        "class LinearRegression:\n",
        "    def __init__(self, X, y):\n",
        "        # Initialize method to set the independent and dependent variables\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.coefficients = None\n",
        "\n",
        "    def dimensionality(self, x):\n",
        "        # Method to get the shape of the input matrix/array\n",
        "        return x.shape\n",
        "\n",
        "    def if_matrix_invertible(self, x):\n",
        "        # Method to check if a matrix is invertible\n",
        "        try:\n",
        "            determinant = np.linalg.det(x)\n",
        "            return determinant != 0\n",
        "        except np.linalg.LinAlgError:\n",
        "            return False\n",
        "\n",
        "    def scale(self,X):\n",
        "        if self.X is not None:\n",
        "            return (X - X.mean()) / X.std()\n",
        "        else:\n",
        "            raise ValueError(\"Input data 'x' is not provided.\")\n",
        "\n",
        "    def train_test_split(self, X, y, train_ratio):\n",
        "        # Method to split the data into training and testing sets based on the provided ratio\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        order = np.array(range(X.shape[0]))\n",
        "        np.random.shuffle(order)\n",
        "        X_shuffled = X[order, :]\n",
        "        y_shuffled = y[order]\n",
        "        train_size = int(X.shape[0] * train_ratio)\n",
        "        X_train, X_test = X[order, :][:train_size+1, :].copy(), X[order, :][train_size+1:, :].copy()\n",
        "        y_train, y_test = y[order][:train_size+1].copy(), y[order][train_size+1:].copy()\n",
        "        return X_train, y_train, X_test, y_test\n",
        "\n",
        "    def compute_coeff(self, X, y):\n",
        "        # Method to compute the coefficients of the linear regression model\n",
        "        self.X = X\n",
        "        ones = np.ones([X.shape[0], 1])  # Creating a column of ones for the bias term\n",
        "        X_new = np.hstack([ones, X])  # Augmenting the data with the ones column\n",
        "        # Calculating the coefficients using the normal equation\n",
        "        return np.matmul(np.linalg.inv(np.matmul(X_new.T, X_new)), np.matmul(X_new.T, y))\n",
        "\n",
        "    def compute_loss(self, y, y_pred):\n",
        "        # Method to compute the Mean Squared Error (MSE) loss\n",
        "        return np.dot(y - y_pred, y - y_pred) / len(y)\n"
      ],
      "metadata": {
        "id": "3ThFrJsh3fwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Import necessary module from scikit-learn\n",
        "    from sklearn.datasets import fetch_california_housing\n",
        "    from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "    # Fetch the California housing dataset\n",
        "    X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "    # Initialize the Linear Regression model with the loaded data\n",
        "    lg = LinearRegression(X, y)\n",
        "    pca = principleComponentAnalysis(X,y)\n",
        "\n",
        "    # Print the dimensions of the loaded data\n",
        "    print(\"DIMENSIONALITY-LinearRegression:\", lg.dimensionality(x=X))\n",
        "    print(\"DIMENSIONALITY-PCA:\", pca.dimensionality(x=X))\n",
        "\n",
        "\n",
        "    # Check and print whether the matrix is invertible\n",
        "    is_invertible = lg.if_matrix_invertible(X)\n",
        "    print(\"\\nIS INVERTIBLE IN LinearRegression:\", is_invertible)\n",
        "    is_invertible = pca.if_matrix_invertible(X)\n",
        "    print(\"\\nIS INVERTIBLE IN PCA:\", is_invertible)\n",
        "\n",
        "    # Scale the data and print the first row of the scaled data\n",
        "    print(\"\\nFIRST ROW AFTER SCALED IN LinearRegression:\\n\")\n",
        "    print(np.apply_along_axis(lg.scale, axis=0, arr=X)[:1])\n",
        "    print(\"\\nFIRST ROW AFTER SCALED IN PCA:\\n\")\n",
        "    print(np.apply_along_axis(pca.scale, axis=0, arr=X)[:1])\n",
        "\n",
        "    X, y = fetch_california_housing(return_X_y=True)\n",
        "    beta = lg.compute_coeff(X,y)\n",
        "    X_raw = np.column_stack((np.ones(X.shape[0]), X))\n",
        "    y_raw_pred = np.dot(X_raw, beta)\n",
        "    print(lg.compute_loss(y,y_raw_pred))\n",
        "\n",
        "    X, y = fetch_california_housing(return_X_y=True)\n",
        "    poly = PolynomialFeatures(degree=3,include_bias=False)\n",
        "    X = poly.fit_transform(X)\n",
        "    X = np.apply_along_axis(pca.scale, axis=0, arr=X)\n",
        "\n",
        "    X_pca = pca.principle_components(X,m=6)\n",
        "    print(X_pca)\n",
        "    beta = lg.compute_coeff(X_pca,y)\n",
        "    X_raw_pca = np.column_stack((np.ones(X_pca.shape[0]), X_pca))\n",
        "    print(X_pca.shape)\n",
        "    y_pca_pred = np.dot(X_raw_pca, beta)\n",
        "    print(lg.compute_loss(y,y_pca_pred))\n",
        "\n",
        "# If the script is being run as the main module, execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "XwVmfcCt3kSY",
        "outputId": "e644988a-1f11-45f0-cd1a-d2f82a584658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIMENSIONALITY-LinearRegression: (20640, 8)\n",
            "DIMENSIONALITY-PCA: (20640, 8)\n",
            "\n",
            "IS INVERTIBLE IN LinearRegression: False\n",
            "\n",
            "IS INVERTIBLE IN PCA: False\n",
            "\n",
            "FIRST ROW AFTER SCALED IN LinearRegression:\n",
            "\n",
            "[[ 2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286  -0.04959654\n",
            "   1.05254828 -1.32783522]]\n",
            "\n",
            "FIRST ROW AFTER SCALED IN PCA:\n",
            "\n",
            "[[ 2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286  -0.04959654\n",
            "   1.05254828 -1.32783522]]\n",
            "0.5243209861846072\n",
            "[[ 1.94515615  6.71743778  3.30807603 11.57833915  1.2853284   2.76127731]\n",
            " [ 2.5910673   2.24610702 -8.39291112  7.82031622  1.89645113  3.54818978]\n",
            " [ 3.02694541  8.61287512  4.84289515 12.20563945 -3.93793978  2.62567431]\n",
            " ...\n",
            " [-1.69929655 -1.53976998  1.47042045 -4.48742037  2.75399914  4.49381542]\n",
            " [-1.74290784 -1.04383443  2.18200422 -4.17075192  3.06295967  4.5349151 ]\n",
            " [-1.11030568 -1.30606462 -0.16200549 -3.81181345  2.54560317  4.53849902]]\n",
            "(20640, 6)\n",
            "0.705328419971186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verifying the answer"
      ],
      "metadata": {
        "id": "rOXDMoxdoKAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_scaling(x):\n",
        "    return (x-x.mean())/x.std()"
      ],
      "metadata": {
        "id": "whywAcKZoJiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "    # Fetch the California housing dataset\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X = np.apply_along_axis(standard_scaling, axis=0, arr=X)\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print (mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGgdxqF6oW5Q",
        "outputId": "3da29a84-2da3-4d6b-cf2e-837379596bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5243209861846072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Instantiate the PCA model with the number of components you want to retain\\\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "poly = PolynomialFeatures(degree=3,include_bias=False)\n",
        "X = poly.fit_transform(X)\n",
        "X = np.apply_along_axis(standard_scaling, axis=0, arr=X)\n",
        "pca = PCA(n_components=6)\n",
        "X_pcaed_sk= pca.fit_transform(X)\n",
        "#print(X_pcaed_sk)\n",
        "model.fit(X_pcaed_sk, y)\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_pcaed_sk)\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(mse)"
      ],
      "metadata": {
        "id": "Qw9nmJ4jodVQ",
        "outputId": "d314ecf5-5ca9-4690-d2d3-5883feb915ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7053284199711828\n"
          ]
        }
      ]
    }
  ]
}